from gensim.models import word2vec
import jieba
import numpy as np

from keras.models import model_from_json


def get_vectored_review(data):
    review = []
    for ph in jieba.cut(data, cut_all=False):
        review.append(ph)
    # print("åˆ†è¯ ç»“æœï¼š", review)
    max_len = 20
    # å¾—åˆ°wordåˆ°indexçš„å¯¹åº”
    model = word2vec.Word2Vec.load('model/word_vec_model.model')
    word2index = {token: token_index for token_index, token in enumerate(model.wv.index2word)}
    max_words = len(word2index) + 1  # word2indexæ‰€æœ‰å•è¯
    numize_review = []
    with open("res/stopwords.txt", encoding='utf-8') as f:
        stopWords = [word.replace("\n", "") for word in f.readlines()]
    # print('review', review)
    for word in review:
        if word in stopWords:
            continue
        # æœªæ‰¾åˆ°å¯¹åº”wordåˆ™è¡¥â€œæ’æ’â€å¯¹åº”çš„index
        try:
            numize_review.append(word2index[word])
        except KeyError:
            numize_review.append(max_words - 1)
    # æ£€æŸ¥é•¿åº¦æ˜¯å¦å¤Ÿmax_lenä¸ª
    r_len = len(numize_review)
    while r_len < max_len:  # ä¸è¶³max_lenä¸ªé•¿åº¦è¡¥ä¸Šå­—ç¬¦"?"çš„index
        numize_review.append(max_words - 1)
        r_len += 1  # è¿‡é•¿åˆ™æˆªå–max_lenä¸ª
    if r_len > max_len:
        numize_review = numize_review[:max_len]
        # print(len())
    return np.asarray([numize_review])  # å¿…é¡»æ˜¯äºŒç»´çš„å“¦


def predict(str_review):
    # åœ¨ä½¿ç”¨åŠ è½½çš„æ¨¡å‹ä¹‹å‰ï¼Œå¿…é¡»å…ˆç¼–è¯‘å®ƒã€‚è¿™æ ·ï¼Œä½¿ç”¨è¯¥æ¨¡å‹è¿›è¡Œçš„é¢„æµ‹å¯ä»¥ä½¿ç”¨Kerasåç«¯çš„é€‚å½“è€Œæœ‰æ•ˆçš„è®¡ç®—ã€‚
    # åŠ è½½æ¨¡å‹å¹¶ä½¿ç”¨model_from_jsonåˆ›å»ºæ¨¡å‹
    json_file = open('model/net_model.json', 'r')
    loaded_model_json = json_file.read()
    json_file.close()
    loaded_model = model_from_json(loaded_model_json)

    # åŠ è½½æƒé‡
    loaded_model.load_weights("model/model_weights.h5")
    print("å·²åŠ è½½æ¨¡å‹ä¸æƒé‡")

    # ç¼–è¯‘æ¨¡å‹
    loaded_model.compile(optimizer='rmsprop',
                         loss='categorical_crossentropy',
                         metrics=['accuracy'])
    # ä¸åŠ è¿™å¥é‚£ä¹ˆFlaskçº¿ç¨‹æ— æ³•è®¿é—®tfçš„é»˜è®¤çº¿ç¨‹ï¼Œä»–ä¼šåˆ›å»ºæ–°çš„tfçº¿ç¨‹
    # ä»è€ŒæŠ¥é”™
    #-------------------------
    # str_review = "ä¸ä¼šå†ä¹°è¿™ä¸ªå“ç‰Œçš„ä¸œè¥¿äº†ï¼è¯ä¸å¤šè¯´ï¼Œç›´æ¥ä¸Šå›¾ï¼"
    # review = ['ä¸€æ˜Ÿéƒ½ä¸æƒ³ç»™ï¼å•†å®¶è¯¯å¯¼æ¶ˆè´¹è€…ï¼Œä¸ä¼šå†ä¹°è¿™ä¸ªå“ç‰Œçš„ä¸œè¥¿äº†ï¼è¯ä¸å¤šè¯´ï¼Œç›´æ¥ä¸Šå›¾ï¼',
    #       'ä¸å¥½æ„æ€è¿™ä¸ªçœ‹é”™äº†è¯„é”™äº†ä½†ä¹Ÿæ²¡æ‰¾åˆ°ä¿®æ”¹åŠæ³•ï¼Œè¿™ä¸ªäº§å“è¿˜æ˜¯å¾ˆä¸é”™çš„å¾ˆæ£’æ£’ï¼Œä½†è¦æ³¨æ„å°±æ˜¯æ”¾ä¸ä¸‹å¸¦æœ‰USBå£æ¯”è¾ƒé•¿çš„æ’çº¿æ¿ï¼Œ']
    str_review = str_review.strip()  # å»é™¤ä¸¤ç«¯ç©ºæ ¼
    # print("è¯„è®ºï¼š", str_review)
    vec = get_vectored_review(str_review)
    result = loaded_model.predict_classes(vec)
    # print("||")
    probs = loaded_model.predict(vec)  # å¥½ä¸­å·®åˆ†åˆ«çš„æ¦‚ç‡å€¼
    # print("||")
    if result == 0:
        cla = 'å·®è¯„ğŸ˜’'
    elif result == 1:
        cla = 'ä¸­è¯„ğŸ˜'
    else:
        cla = 'å¥½è¯„ğŸ‘'
    # print(cla)
    str_probs = []
    for i in probs[0]:
        str_probs.append(str(i))
    return cla, str_probs


# x, y = predict('å¥½è¯„')
# print(type(x))
# print(y)
# print(type(list(y)))